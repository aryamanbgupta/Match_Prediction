{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "basepath = Path('/Users/aryamangupta/CricML/Match_Prediction/')\n",
    "data_folder_path = basepath / 'data' / 'ipl_json'\n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "\n",
    "for json_path in sorted(data_folder_path.glob('*.json')):\n",
    "    with json_path.open() as f:\n",
    "        json_data = f.read()\n",
    "        match_data = json.loads(json_data)\n",
    "        # print (data['info'])\n",
    "        \n",
    "        for inning in match_data['innings']:\n",
    "            match_dataset = []\n",
    "            for over in inning['overs']:\n",
    "                for delivery in over['deliveries']:\n",
    "                    if 'wickets' in delivery:\n",
    "                        match_dataset.append('W')\n",
    "                    else:\n",
    "                        match_dataset.append(str(delivery['runs']['total']))\n",
    "            dataset.append(match_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# print(dataset[0][11])\n",
    "all_runs = [run for match in dataset for run in match]\n",
    "runs = sorted(list(set(all_runs)))\n",
    "print(runs)\n",
    "stoi = {s:i+1 for i,s in enumerate(runs)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 30\n",
    "X,Y = [], []\n",
    "for match in dataset:\n",
    "    #print (match[:11])\n",
    "    context = [0]* block_size\n",
    "    for outcome in match:\n",
    "        ix = stoi[outcome]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(','.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([260920, 30]), torch.int64, torch.Size([260920]), torch.int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn (10,2)\n",
    "W1 = torch.randn((60,100))\n",
    "b1 = torch.randn(100)\n",
    "W2 = torch.randn((100,10))\n",
    "b2 = torch.randn(10)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.329028129577637\n",
      "6.051759719848633\n",
      "5.900296211242676\n",
      "5.426515579223633\n",
      "5.228805065155029\n",
      "5.0076093673706055\n",
      "4.930269718170166\n",
      "4.453269004821777\n",
      "4.243190765380859\n",
      "4.22750997543335\n",
      "4.330288410186768\n",
      "4.416965484619141\n",
      "3.6963930130004883\n",
      "3.707919120788574\n",
      "3.6851186752319336\n",
      "3.6472973823547363\n",
      "3.292001962661743\n",
      "3.2441422939300537\n",
      "2.954390525817871\n",
      "2.9557406902313232\n",
      "2.7031056880950928\n",
      "2.7652230262756348\n",
      "2.4557297229766846\n",
      "2.530885934829712\n",
      "2.2571029663085938\n",
      "2.330965280532837\n",
      "2.088730812072754\n",
      "2.172010660171509\n",
      "1.9471226930618286\n",
      "2.0465028285980225\n",
      "1.8286080360412598\n",
      "1.9205775260925293\n",
      "1.6876355409622192\n",
      "1.7245845794677734\n",
      "1.4955064058303833\n",
      "1.4669914245605469\n",
      "1.3349974155426025\n",
      "1.290486454963684\n",
      "1.2130588293075562\n",
      "1.1599292755126953\n",
      "1.1272655725479126\n",
      "1.0473865270614624\n",
      "1.0523293018341064\n",
      "0.9372158050537109\n",
      "0.9396460652351379\n",
      "0.8284508585929871\n",
      "0.829930305480957\n",
      "0.7334187626838684\n",
      "0.7319384217262268\n",
      "0.6494004130363464\n",
      "0.6399528980255127\n",
      "0.5741868019104004\n",
      "0.5587348341941833\n",
      "0.5137806534767151\n",
      "0.49613821506500244\n",
      "0.46726736426353455\n",
      "0.44884544610977173\n",
      "0.4280158579349518\n",
      "0.40897950530052185\n",
      "0.3916734755039215\n",
      "0.37287387251853943\n",
      "0.3572956621646881\n",
      "0.34043487906455994\n",
      "0.3265824615955353\n",
      "0.31282228231430054\n",
      "0.301095575094223\n",
      "0.29011330008506775\n",
      "0.2802550196647644\n",
      "0.2710709273815155\n",
      "0.2625104784965515\n",
      "0.25442495942115784\n",
      "0.2467469871044159\n",
      "0.23942069709300995\n",
      "0.23240943253040314\n",
      "0.22568611800670624\n",
      "0.21922942996025085\n",
      "0.21302153170108795\n",
      "0.20704694092273712\n",
      "0.2012917548418045\n",
      "0.1957433670759201\n",
      "0.19039063155651093\n",
      "0.18522292375564575\n",
      "0.18023081123828888\n",
      "0.17540551722049713\n",
      "0.17073893547058105\n",
      "0.16622360050678253\n",
      "0.16185250878334045\n",
      "0.15761931240558624\n",
      "0.15351778268814087\n",
      "0.14954215288162231\n",
      "0.1456870436668396\n",
      "0.14194712042808533\n",
      "0.13831768929958344\n",
      "0.13479389250278473\n",
      "0.13137130439281464\n",
      "0.12804576754570007\n",
      "0.1248130351305008\n",
      "0.12166948616504669\n",
      "0.11861161887645721\n",
      "0.11563605815172195\n"
     ]
    }
   ],
   "source": [
    "for _ in range (10):\n",
    "    #forward pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1,60) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
